{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 49s 0us/step\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:175: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:180: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:184: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:193: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:200: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1801: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:127: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3014: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:977: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ggaar\\Anaconda3\\envs\\cvMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:964: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 84s 2ms/step - loss: 1.5473 - acc: 0.4504\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 88s 2ms/step - loss: 1.1732 - acc: 0.5830\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.0035 - acc: 0.6448\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 0.8454 - acc: 0.7035\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 126s 3ms/step - loss: 0.6906 - acc: 0.7563\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 119s 2ms/step - loss: 0.5448 - acc: 0.8112\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.4161 - acc: 0.8570\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.3158 - acc: 0.8935\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.2362 - acc: 0.9199\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 97s 2ms/step - loss: 0.1934 - acc: 0.9360\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 98s 2ms/step - loss: 0.1603 - acc: 0.9449\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 0.1507 - acc: 0.9493\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.1336 - acc: 0.9544\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1095 - acc: 0.9644\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0959 - acc: 0.9688\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 117s 2ms/step - loss: 0.0969 - acc: 0.9665\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 0.0916 - acc: 0.9693\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 0.0962 - acc: 0.9672\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0864 - acc: 0.9705: 0s - loss: 0.0859 - acc: 0\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.0765 - acc: 0.9743\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.0620 - acc: 0.9792\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 89s 2ms/step - loss: 0.0616 - acc: 0.9799\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 97s 2ms/step - loss: 0.0731 - acc: 0.9747\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.0809 - acc: 0.9728\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 98s 2ms/step - loss: 0.0717 - acc: 0.9765: 2s - loss: 0.0710 -\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 97s 2ms/step - loss: 0.0615 - acc: 0.9794\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0533 - acc: 0.9817\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0526 - acc: 0.9827\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 89s 2ms/step - loss: 0.0520 - acc: 0.9832\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 0.0509 - acc: 0.9830\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0579 - acc: 0.9799\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0626 - acc: 0.9799\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.0572 - acc: 0.9812\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 87s 2ms/step - loss: 0.0380 - acc: 0.9872: 2s - loss: 0.0381\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 96s 2ms/step - loss: 0.0298 - acc: 0.9906\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 89s 2ms/step - loss: 0.0458 - acc: 0.9854\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 88s 2ms/step - loss: 0.0504 - acc: 0.9836\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0472 - acc: 0.9847\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0437 - acc: 0.9852\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0429 - acc: 0.9861\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0368 - acc: 0.9877\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 116s 2ms/step - loss: 0.0337 - acc: 0.9887\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0416 - acc: 0.9859\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 0.0394 - acc: 0.9872\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 0.0358 - acc: 0.9884\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0380 - acc: 0.9874\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0318 - acc: 0.9895\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 120s 2ms/step - loss: 0.0397 - acc: 0.9872\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 116s 2ms/step - loss: 0.0418 - acc: 0.9865\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 121s 2ms/step - loss: 0.0302 - acc: 0.9907\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 116s 2ms/step - loss: 0.0270 - acc: 0.9913\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.0240 - acc: 0.9920\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 98s 2ms/step - loss: 0.0294 - acc: 0.9906\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0470 - acc: 0.9846\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 97s 2ms/step - loss: 0.0338 - acc: 0.9894\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0291 - acc: 0.9905\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0240 - acc: 0.9922\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 97s 2ms/step - loss: 0.0265 - acc: 0.9915\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 88s 2ms/step - loss: 0.0253 - acc: 0.9918\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0299 - acc: 0.9901\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 96s 2ms/step - loss: 0.0307 - acc: 0.9901\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 97s 2ms/step - loss: 0.0258 - acc: 0.9915\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0284 - acc: 0.9914\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 89s 2ms/step - loss: 0.0226 - acc: 0.9928\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0281 - acc: 0.9911\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.0318 - acc: 0.9896\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 0.0267 - acc: 0.9912\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 0.0233 - acc: 0.9926\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 114s 2ms/step - loss: 0.0184 - acc: 0.9937\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0207 - acc: 0.9937\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0310 - acc: 0.9899\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 0.0255 - acc: 0.9919\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0204 - acc: 0.9937\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 0.0197 - acc: 0.9936\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 0.0242 - acc: 0.9923\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 97s 2ms/step - loss: 0.0212 - acc: 0.9933\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 87s 2ms/step - loss: 0.0246 - acc: 0.9916\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 0.0254 - acc: 0.9919\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 0.0151 - acc: 0.9953\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 97s 2ms/step - loss: 0.0148 - acc: 0.9949\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 0.0227 - acc: 0.9928\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 0.0308 - acc: 0.9901: 3s - loss: 0.0301 - - ETA: 0s - loss: 0.0306 - acc: 0\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 0.0197 - acc: 0.9934\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 98s 2ms/step - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 88s 2ms/step - loss: 0.0180 - acc: 0.9947\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 0.0251 - acc: 0.9922\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0274 - acc: 0.9918\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 86s 2ms/step - loss: 0.0212 - acc: 0.9934\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 89s 2ms/step - loss: 0.0162 - acc: 0.9942\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0149 - acc: 0.9946\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0105 - acc: 0.9967\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0210 - acc: 0.9931\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0283 - acc: 0.9915\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 0.0241 - acc: 0.9923\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0164 - acc: 0.9950\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.0148 - acc: 0.9954\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.0120 - acc: 0.9960\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 125s 2ms/step - loss: 0.0118 - acc: 0.9962\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 121s 2ms/step - loss: 0.0169 - acc: 0.9942\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 0.0224 - acc: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2318d4a5e88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(filters = 32, kernel_size = 3, padding='same', input_shape=(32,32,3), activation='relu'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(filters = 3, kernel_size = 3, padding='same', activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim=100, activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.8202605e-10, 5.3709743e-26, 5.4144497e-08, 9.9999988e-01,\n",
       "        3.3302291e-11, 3.9172949e-09, 8.7855976e-13, 1.5293415e-07,\n",
       "        9.1764679e-11, 6.4712970e-18]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
